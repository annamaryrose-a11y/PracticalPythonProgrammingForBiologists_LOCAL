{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y4AK8T2UmTw"
      },
      "source": [
        "# Practical Python Programming for Biologists\n",
        "Author: Dr. Daniel Pass | www.CompassBioinformatics.com\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxikhAFLUpPh"
      },
      "source": [
        "---\n",
        "\n",
        "# Day 2 Project - More strings & loops - and very messy data\n",
        "\n",
        "Data is messy. Biologist data even more so. Here we have some data on bacterial abundance as collected by some well meaning scientists but unfortunately it's a bit of a mess. It is technically in a four column format liks this, howver when you look below it's mixed up:\n",
        "\n",
        "```\n",
        "| Collector | Percentage abundance | Dominant Phyla | Date |\n",
        "```\n",
        "\n",
        "Delimeters:\n",
        "- Between collected sample records: ```,```\n",
        "- Between data fields per sample: ```-```\n",
        "\n",
        "We want to clean up the data and make some sense out of it. **The objective is to output a count of the number of samples with a high proportion of each phyla.**\n",
        "\n",
        "1. Look at the text file first so that you know what we are looking at!\n",
        "2. We will read in the file ```MessyData.txt``` with ```open()``` as one object (it is too mixed-up to read line-by-line), and then split based on the delimiters above. We will learn more about loading files in the IO session.\n",
        "\n",
        "If you want to challange yourself try to clean the data first before looking in this guide section!\n",
        "I recommend using ```print()``` functions after each step to check the output is as expected.\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "<summary>Step-by-step guide</summary>\n",
        "\n",
        "2. First split the data by commas into a new list of ```records``` with the function ```.split()```\n",
        "2. Create a new loop to go through your ```records``` list and split each record by ```-``` into the 4 data elements (put the output into a new list too)\n",
        "3. Create a **2D/nested** loop for your latest list, to remove the whitepace off each element with ```.strip()```. (First go through each record, then through each element. Make sure to keep experiments together!)\n",
        "4. Create a long list of all the dominant phyla per sample (The third column of the data) - some samples have multiple phyla, so have to be split again first! Careful here, because you want a basic list, not a list of lists.\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "5. Print out your new clean dataframe!\n",
        "\n",
        "**Extensions**\n",
        "1. Calculate the average abundance per collection date (4 options) (use ```if date_column == ....```. We'll look at automatically building lists later)\n",
        "2. Output a clean list of all named phyla from the data column in a list named ```phyla_count```. There may be more than one phyla in the list per sample. There is a codeblock at the end that will count for each of the list I've given you, and summarise your output for a list of phyla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xCi8rep_TvGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10ac411-4546-4aa8-b7f5-ec55cb349dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dominant phyla observed in the samples were as follows:\n",
            " ['Chloroflexi', 'Chloroflexi', 'Acidobacteria', 'Chloroflexi', 'Acidobacteria', 'Chloroflexi', 'Chloroflexi', 'Bacillus', 'Actinomycetes', 'Actinomycetes', 'Bacillus', 'Actinomycetes', 'Bacillus', 'Acidobacteria', 'Acidobacteria', 'Actinomycetes', 'Acidobacteria', 'Chloroflexi', 'Chloroflexi', 'Firmicutes', 'Chloroflexi', 'Acidobacteria', 'Firmicutes', 'Acidobacteria', 'Proteobacteria', 'Acidobacteria', 'Proteobacteria', 'Acidobacteria', 'Firmicutes', 'Proteobacteria', 'Acidobacteria', 'Firmicutes', 'Cyanobacteria', 'Cyanobacteria', 'Bacillus', 'Chloroflexi', 'Cyanobacteria', 'Bacillus', 'Chloroflexi', 'Cyanobacteria', 'Bacillus', 'Proteobacteria', 'Proteobacteria', 'Bacillus', 'Proteobacteria', 'Bacillus', 'Acidobacteria', 'Proteobacteria', 'Bacillus', 'Actinomycetes', 'Acidobacteria', 'Cyanobacteria', 'Cyanobacteria', 'Acidobacteria', 'Cyanobacteria', 'Acidobacteria', 'Cyanobacteria', 'Cyanobacteria', 'Actinomycetes', 'Cyanobacteria', 'Actinomycetes', 'Bacillus', 'Bacillus', 'Firmicutes', 'Bacillus', 'Bacillus', 'Acidobacteria', 'Bacillus', 'Acidobacteria', 'Firmicutes', 'Cyanobacteria', 'Cyanobacteria', 'Firmicutes', 'Cyanobacteria', 'Firmicutes', 'Chloroflexi', 'Cyanobacteria', 'Firmicutes', 'Bacillus', 'Bacillus', 'Cyanobacteria', 'Proteobacteria', 'Bacillus', 'Cyanobacteria', 'Bacillus', 'Chloroflexi', 'Bacillus', 'Chloroflexi', 'Bacillus', 'Cyanobacteria', 'Bacillus', 'Bacillus', 'Chloroflexi', 'Chloroflexi', 'Cyanobacteria', 'Chloroflexi', 'Cyanobacteria', 'Chloroflexi', 'Cyanobacteria', 'Firmicutes', 'Actinomycetes', 'Actinomycetes', 'Bacillus', 'Actinomycetes', 'Bacillus', 'Proteobacteria', 'Actinomycetes', 'Bacillus', 'Firmicutes', 'Bacillus', 'Firmicutes', 'Proteobacteria', 'Bacillus', 'Firmicutes', 'Firmicutes', 'Proteobacteria', 'Firmicutes', 'Proteobacteria', 'Chloroflexi', 'Firmicutes', 'Chloroflexi', 'Chloroflexi', 'Firmicutes', 'Actinomycetes', 'Actinomycetes', 'Proteobacteria', 'Proteobacteria', 'Proteobacteria', 'Firmicutes', 'Chloroflexi', 'Firmicutes', 'Chloroflexi', 'Actinomycetes', 'Firmicutes', 'Firmicutes', 'Cyanobacteria', 'Firmicutes', 'Cyanobacteria', 'Firmicutes', 'Cyanobacteria', 'Firmicutes', 'Proteobacteria', 'Proteobacteria', 'Bacillus', 'Proteobacteria', 'Bacillus', 'Acidobacteria', 'Actinomycetes', 'Actinomycetes', 'Cyanobacteria', 'Bacillus', 'Bacillus', 'Bacillus', 'Acidobacteria', 'Proteobacteria', 'Proteobacteria', 'Chloroflexi', 'Chloroflexi', 'Acidobacteria', 'Chloroflexi', 'Cyanobacteria', 'Acidobacteria', 'Proteobacteria', 'Proteobacteria', 'Bacillus', 'Proteobacteria', 'Bacillus', 'Cyanobacteria', 'Proteobacteria', 'Proteobacteria', 'Proteobacteria', 'Actinomycetes', 'Proteobacteria', 'Proteobacteria', 'Chloroflexi', 'Proteobacteria', 'Chloroflexi', 'Acidobacteria', 'Proteobacteria', 'Chloroflexi', 'Acidobacteria']\n"
          ]
        }
      ],
      "source": [
        "# Read file in as one block because too messy to read line by line\n",
        "with open(\"/content/Day2-Project-MessyData.txt\") as inFile:\n",
        "  data = inFile.read()\n",
        "\n",
        "data = data.replace(\"%\", \" \")\n",
        "\n",
        "data = data.strip()\n",
        "\n",
        "#separate out each entry by the dividing ,\n",
        "\n",
        "records = data.split(\",\")\n",
        "\n",
        "#make new nested list separating each record at -\n",
        "\n",
        "data_points_separate = []\n",
        "\n",
        "for data_point in records :\n",
        "  data_points_separate.append(data_point.split(\"-\"))\n",
        "\n",
        "#make nested loop so that the parts of the nested list are cleaned (list cant be stripped only string) - need to append twice!\n",
        "\n",
        "data_points_separate_cleaned = []\n",
        "\n",
        "for parts in data_points_separate:\n",
        "    cleaned_parts = []\n",
        "    for part in parts:\n",
        "        cleaned_parts.append(part.strip())\n",
        "    data_points_separate_cleaned.append(cleaned_parts)\n",
        "\n",
        "#print (data_points_separate_cleaned)\n",
        "# select out index2 (3rd item) and split at &\n",
        "\n",
        "dominant_phyla_raw = []\n",
        "\n",
        "for individual_record in data_points_separate_cleaned :\n",
        "  dominant_phyla_raw.append(individual_record[2])\n",
        "\n",
        "\n",
        "dominant_phyla_splitup = []\n",
        "\n",
        "for bugs in dominant_phyla_raw :\n",
        "  dominant_phyla_splitup.append(bugs.split(\"&\"))\n",
        "\n",
        "#flatten the list so no nesting\n",
        "\n",
        "dominant_phyla_separated = []\n",
        "for sublist in dominant_phyla_splitup:\n",
        "    for item in sublist:\n",
        "        dominant_phyla_separated.append(item)\n",
        "\n",
        "print (\"The dominant phyla observed in the samples were as follows:\\n\", dominant_phyla_separated)\n",
        "\n",
        "phyla_count = dominant_phyla_separated\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBToCNIrhz0E",
        "outputId": "80a23bc4-691f-4a91-8456-c9907287ae31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phylum\t\tCount\n",
            "Actinomycetes \t 17\n",
            "Proteobacteria \t 30\n",
            "Cyanobacteria \t 26\n",
            "Firmicutes \t 24\n",
            "Chloroflexi \t 28\n",
            "Acidobacteria \t 22\n",
            "Bacillus \t 34\n"
          ]
        }
      ],
      "source": [
        "# Name your final clean list of all phyla \"phyla_count\", then test it with this code block\n",
        "phyla = ['Actinomycetes', 'Proteobacteria', 'Cyanobacteria', 'Firmicutes', 'Chloroflexi', 'Acidobacteria', 'Bacillus']\n",
        "\n",
        "print(\"Phylum\\t\\tCount\")\n",
        "for p in phyla:\n",
        "    print(p, \"\\t\", phyla_count.count(p))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection_dates =[\"15/03/22\", \"04/05/22\", \"21/06/22\", \"01/08/22\"]\n",
        "\n",
        "abundance_by_date = {date: [] for date in collection_dates}\n",
        "\n",
        "for record in data_points_separate_cleaned:\n",
        "    record_date = record[3] #4th item in nested record\n",
        "    if record_date in abundance_by_date:   # only looks for dates in the collection_dates list/dictionary\n",
        "        abundance_by_date[record_date].append(record[1])\n",
        "\n",
        "abundance_march = abundance_by_date[\"15/03/22\"]\n",
        "abundance_may = abundance_by_date[\"04/05/22\"]\n",
        "abundance_june = abundance_by_date[\"21/06/22\"]\n",
        "abundance_august = abundance_by_date[\"01/08/22\"]\n",
        "\n",
        "sum_march = sum(float(values) for values in abundance_march)\n",
        "sum_may = sum(float(values) for values in abundance_may)\n",
        "sum_june = sum(float(values) for values in abundance_june)\n",
        "sum_august = sum(float(values) for values in abundance_august)\n",
        "\n",
        "average_abundance_march = round(sum_march/len(abundance_march),3)\n",
        "average_abundance_may = round(sum_may/len(abundance_may),3)\n",
        "average_abundance_june = round(sum_june/len(abundance_june),3)\n",
        "average_abundance_august = round(sum_august/len(abundance_august),3)\n",
        "\n",
        "print (average_abundance_march)\n",
        "print (average_abundance_may)\n",
        "print (average_abundance_june)\n",
        "print (average_abundance_august)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j5ptTSqu9fh",
        "outputId": "bc1c8b48-aea5-4168-9196-438c97f3cb66"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.32\n",
            "14.322\n",
            "20.389\n",
            "12.347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can i loop it?\n",
        "\n",
        "\n",
        "collection_dates =[\"15/03/22\", \"04/05/22\", \"21/06/22\", \"01/08/22\", \"01/01/22\"]\n",
        "\n",
        "abundance_by_date = {date: [] for date in collection_dates}\n",
        "\n",
        "for record in data_points_separate_cleaned:\n",
        "    record_date = record[3] #4th item in nested record\n",
        "    if record_date in abundance_by_date:   # only looks for dates in the collection_dates dictionary\n",
        "        abundance_by_date[record_date].append(record[1]) #adds index item to the dictionary if date has been found\n",
        "\n",
        "averages_by_date = {}\n",
        "\n",
        "for date, abundances in abundance_by_date.items():\n",
        "    if abundances: #means not broken by a null entry\n",
        "        total = sum(float(value) for value in abundances)\n",
        "        averages_by_date[date] = round(total / len(abundances), 3)\n",
        "    else:\n",
        "        averages_by_date[date] = None\n",
        "\n",
        "print (averages_by_date)\n",
        "\n",
        "#MY BRAIN HURTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWDyRZcPyMma",
        "outputId": "9325eacf-36af-4f66-8281-ce0cb6734a99"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'15/03/22': 13.32, '04/05/22': 14.322, '21/06/22': 20.389, '01/08/22': 12.347, '01/01/22': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQx5fpGr4Lzm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}